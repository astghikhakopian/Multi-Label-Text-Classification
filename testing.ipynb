{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tools.Tokenizer.tokenizer import Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('armenian')) \n",
    "\n",
    "# Helpers\n",
    "def tokenize(text):\n",
    "    T = Tokenizer(text)\n",
    "    T.segmentation().tokenization()\n",
    "    word_tokens = []\n",
    "    for segment in T.segments:\n",
    "        for token in segment['tokens']:\n",
    "            word_tokens.append(token[1].lower())\n",
    "    return word_tokens\n",
    "\n",
    "def remove_stopwords(word_tokens):\n",
    "    filtered_word_tokens = [w for w in word_tokens if not w in stop_words]\n",
    "    return filtered_word_tokens\n",
    "\n",
    "def stemming(word_tokens):\n",
    "    stemmer = SnowballStemmer(\"armenian\") \n",
    "    filtered_word_tokens = [ stemmer.stem(w) for w in word_tokens ]\n",
    "    return filtered_word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "# vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "# BinaryRelevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training data\n",
    "df = pd.read_csv('data/clean/Trainning_reviews.csv')\n",
    "initial_df = pd.read_csv('data/clean/Trainning_reviews.csv')\n",
    "\n",
    "# cleaning up text\n",
    "df['Description'] = df['Description'].apply(lambda row : row + '։') \n",
    "df['Description'] = df['Description'].apply(tokenize)\n",
    "\n",
    "df['Description'] = df['Description'].apply(remove_stopwords)\n",
    "df['Description'] = df['Description'].apply(stemming)\n",
    "df['Description'] = df['Description'].apply(lambda row : ' '.join(row)) \n",
    "\n",
    "df.rename(columns = {'Symptoms':'symptom_list'}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract symptoms\n",
    "symptoms = [] \n",
    "\n",
    "for i in df['symptom_list']: \n",
    "    symptoms.append(i.split(', ')) \n",
    "# add to  dataframe  \n",
    "df['Symptoms'] = symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all symptom tags in a list\n",
    "all_symptoms = sum(symptoms,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_symptoms = nltk.FreqDist(all_symptoms) \n",
    "# create dataframe\n",
    "all_symptoms_df = pd.DataFrame({'Symtom': list(all_symptoms.keys()), \n",
    "'Count': list(all_symptoms.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df['Symptoms'])\n",
    "# transform target variable\n",
    "y = multilabel_binarizer.transform(df['Symptoms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into training and validation set\n",
    "xtrain, xval, ytrain, yval = train_test_split(df['Description'], y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TF-IDF features\n",
    "xtrain_tfidf = tfidf_vectorizer.fit_transform(xtrain)\n",
    "xval_tfidf = tfidf_vectorizer.transform(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Relevance\n",
    "br_classifier = BinaryRelevance(LogisticRegression(C=40,class_weight='balanced'))\n",
    "br_classifier.fit(xtrain_tfidf, ytrain)\n",
    "br_predictions = br_classifier.predict(xval_tfidf)\n",
    "\n",
    "print(\"Accuracy = \",accuracy_score(yval,br_predictions.toarray()))\n",
    "print(\"F1 score = \",f1_score(yval,br_predictions, average=\"micro\"))\n",
    "print(\"Hamming loss = \",hamming_loss(yval,br_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_tags(q):\n",
    "    print(q)\n",
    "    q_vec = tfidf_vectorizer.transform([q])\n",
    "\n",
    "    q_pred = br_classifier.predict(q_vec)\n",
    "    return multilabel_binarizer.inverse_transform(q_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5): \n",
    "    k = xval.sample(1).index[0] \n",
    "    print(\"Կարծիք: \", initial_df['Description'][k])\n",
    "    print(\"Կանխատեսում: \", infer_tags(xval[k]))\n",
    "    print(\"Իրականություն: \",df['Symptoms'][k], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"մաշկիս վրա պզուկներ են առաջացել։ դուրս է թափվել։ հետ տալ։\"\n",
    "tokenized = tokenize(text)\n",
    "stopwords_removed = remove_stopwords(tokenized)\n",
    "stemmed = stemming(stopwords_removed)\n",
    "cleanedText = ' '.join(stemmed)\n",
    "print(cleanedText)\n",
    "infer_tags(cleanedText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "q = model.infer_tags(cleanedText)\n",
    "q[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(text):\n",
    "    tokenized = tokenize(text+\"։\")\n",
    "    stopwords_removed = remove_stopwords(tokenized)\n",
    "    stemmed = stemming(stopwords_removed)\n",
    "    cleanedText = ' '.join(stemmed)\n",
    "    return cleanedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up(\"մաշկիս վրա պզուկներ են առաջացել։ դուրս է թափվել։ հետ տալ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "import pickle\n",
    "\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model.py, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "# vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "# BinaryRelevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import TextCleaningHelper\n",
    "\n",
    "\n",
    "# Load Training data\n",
    "df = pd.read_csv('data/clean/Trainning_reviews.csv')\n",
    "initial_df = pd.read_csv('data/clean/Trainning_reviews.csv')\n",
    "\n",
    "# cleaning up datasource \n",
    "df['Description'] = df['Description'].apply(TextCleaningHelper.clean_up)\n",
    "\n",
    "df.rename(columns = {'Symptoms':'symptom_list'}, inplace = True) \n",
    "\n",
    "# extract symptoms\n",
    "symptoms = [] \n",
    "\n",
    "for i in df['symptom_list']: \n",
    "    symptoms.append(i.split(', ')) \n",
    "# add to  dataframe  \n",
    "df['Symptoms'] = symptoms\n",
    "\n",
    "# get all symptom tags in a list\n",
    "all_symptoms = sum(symptoms,[])\n",
    "\n",
    "all_symptoms = nltk.FreqDist(all_symptoms) \n",
    "# create dataframe\n",
    "all_symptoms_df = pd.DataFrame({'Symtom': list(all_symptoms.keys()), \n",
    "'Count': list(all_symptoms.values())})\n",
    "\n",
    "# Vectorization\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df['Symptoms'])\n",
    "# transform target variable\n",
    "y = multilabel_binarizer.transform(df['Symptoms'])\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)\n",
    "\n",
    "# split dataset into training and validation set\n",
    "xtrain, xval, ytrain, yval = train_test_split(df['Description'], y, test_size=0.2, random_state=9)\n",
    "\n",
    "# create TF-IDF features\n",
    "xtrain_tfidf = tfidf_vectorizer.fit_transform(xtrain)\n",
    "xval_tfidf = tfidf_vectorizer.transform(xval)\n",
    "\n",
    "# Binary Relevance\n",
    "br_classifier = BinaryRelevance(LogisticRegression(C=40,class_weight='balanced'))\n",
    "br_classifier.fit(xtrain_tfidf, ytrain)\n",
    "br_predictions = br_classifier.predict(xval_tfidf)\n",
    "\n",
    "print(\"Accuracy = \",accuracy_score(yval,br_predictions.toarray()))\n",
    "print(\"F1 score = \",f1_score(yval,br_predictions, average=\"micro\"))\n",
    "print(\"Hamming loss = \",hamming_loss(yval,br_predictions))\n",
    "\n",
    "# public methods\n",
    "def infer_tags(q):\n",
    "    q_vec = tfidf_vectorizer.transform([q])\n",
    "    q_pred = br_classifier.predict(q_vec)\n",
    "    return multilabel_binarizer.inverse_transform(q_pred)\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(br_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, url_for, request, jsonify\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "loaded_model = pickle.load(open(\"finalized_model.sav\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_tags(q):\n",
    "    q_vec = tfidf_vectorizer.transform([q])\n",
    "    q_pred = loaded_model.predict(q_vec)\n",
    "    return multilabel_binarizer.inverse_transform(q_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_tags(\"հետ տալ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "# vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import TextCleaningHelper\n",
    "\n",
    "# Load Training data\n",
    "df = pd.read_csv('data/clean/Trainning_reviews.csv')\n",
    "initial_df = pd.read_csv('data/clean/Trainning_reviews.csv')\n",
    "\n",
    "# cleaning up datasource \n",
    "df['Description'] = df['Description'].apply(TextCleaningHelper.clean_up)\n",
    "\n",
    "df.rename(columns = {'Symptoms':'symptom_list'}, inplace = True) \n",
    "\n",
    "# extract symptoms\n",
    "symptoms = [] \n",
    "\n",
    "for i in df['symptom_list']: \n",
    "    symptoms.append(i.split(', ')) \n",
    "# add to  dataframe  \n",
    "df['Symptoms'] = symptoms\n",
    "\n",
    "# get all symptom tags in a list\n",
    "all_symptoms = sum(symptoms,[])\n",
    "\n",
    "all_symptoms = nltk.FreqDist(all_symptoms) \n",
    "# create dataframe\n",
    "all_symptoms_df = pd.DataFrame({'Symtom': list(all_symptoms.keys()), \n",
    "'Count': list(all_symptoms.values())})\n",
    "\n",
    "# Vectorization\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df['Symptoms'])\n",
    "# transform target variable\n",
    "y = multilabel_binarizer.transform(df['Symptoms'])\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)\n",
    "\n",
    "# split dataset into training and validation set\n",
    "xtrain, xval, ytrain, yval = train_test_split(df['Description'], y, test_size=0.2, random_state=9)\n",
    "\n",
    "# create TF-IDF features\n",
    "xtrain_tfidf = tfidf_vectorizer.fit_transform(xtrain)\n",
    "xval_tfidf = tfidf_vectorizer.transform(xval)\n",
    "\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'tfidf_vectorizer_model.sav'\n",
    "pickle.dump(tfidf_vectorizer, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "# vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import TextCleaningHelper\n",
    "\n",
    "# Load Training data\n",
    "df = pd.read_csv('data/clean/Trainning_reviews.csv')\n",
    "initial_df = pd.read_csv('data/clean/Trainning_reviews.csv')\n",
    "\n",
    "# cleaning up datasource \n",
    "df['Description'] = df['Description'].apply(TextCleaningHelper.clean_up)\n",
    "\n",
    "df.rename(columns = {'Symptoms':'symptom_list'}, inplace = True) \n",
    "\n",
    "# extract symptoms\n",
    "symptoms = [] \n",
    "\n",
    "for i in df['symptom_list']: \n",
    "    symptoms.append(i.split(', ')) \n",
    "# add to  dataframe  \n",
    "df['Symptoms'] = symptoms\n",
    "\n",
    "# get all symptom tags in a list\n",
    "all_symptoms = sum(symptoms,[])\n",
    "\n",
    "all_symptoms = nltk.FreqDist(all_symptoms) \n",
    "# create dataframe\n",
    "all_symptoms_df = pd.DataFrame({'Symtom': list(all_symptoms.keys()), \n",
    "'Count': list(all_symptoms.values())})\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df['Symptoms'])\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'multilabel_binarizer_model.sav'\n",
    "pickle.dump(multilabel_binarizer, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'itching', 'name': 'Քոր'}, {'label': 'skin_rash', 'name': 'մաշկի ցան'}, {'label': 'nodal_skin_eruptions', 'name': 'Բշտիկներ'}, {'label': 'continuous_sneezing', 'name': 'Շարունակական  փռշտոց'}, {'label': 'shivering', 'name': 'դողէրոցք'}, {'label': 'chills', 'name': 'սարսուռ'}, {'label': 'joint_pain', 'name': 'հոդերի ցավ'}, {'label': 'stomach_pain', 'name': 'ստամոքսի ցավ '}, {'label': 'acidity', 'name': 'թթվայնություն'}, {'label': 'ulcers_on_tongue', 'name': 'բշտիկներ լեզվի վրա'}, {'label': 'muscle_wasting', 'name': 'մկանների թուլացում'}, {'label': 'vomiting', 'name': 'փսխում'}, {'label': 'burning_micturition', 'name': 'այրվող միզել'}, {'label': 'spotting_urination', 'name': 'միզել'}, {'label': 'fatigue', 'name': 'հոգնածություն'}, {'label': 'weight_gain', 'name': 'քաշի ավելացում'}, {'label': 'anxiety', 'name': 'անհանգստություն'}, {'label': 'cold_hands_and_feets', 'name': 'սառը ձեռքեր եւ ոտքեր'}, {'label': 'mood_swings', 'name': 'տրամադրության տատանումներ'}, {'label': 'weight_loss', 'name': 'քաշի կորուստ'}, {'label': 'restlessness', 'name': 'անհանգստություն'}, {'label': 'lethargy', 'name': 'թմրածություն'}, {'label': 'patches_in_throat', 'name': 'մասնիկներ կոկորդում'}, {'label': 'irregular_sugar_level', 'name': 'շաքարի անկանոն մակարդակ'}, {'label': 'cough', 'name': 'հազ'}, {'label': 'high_fever', 'name': 'բարձր ջերմություն'}, {'label': 'sunken_eyes', 'name': 'փոս ընկած աչքեր'}, {'label': 'breathlessness', 'name': 'շնչահեղձություն'}, {'label': 'sweating', 'name': 'Բարձր քրտնաարտադրություն'}, {'label': 'dehydration', 'name': 'ջրազրկում'}, {'label': 'indigestion', 'name': 'Վատ մարսողություն '}, {'label': 'headache', 'name': 'գլխացավ'}, {'label': 'yellowish_skin', 'name': 'դեղնավուն մաշկ'}, {'label': 'dark_urine', 'name': 'մուգ մեզ'}, {'label': 'nausea', 'name': 'սրտխառնոց'}, {'label': 'loss_of_appetite', 'name': 'ախորժակի կորուստ'}, {'label': 'pain_behind_the_eyes', 'name': 'ցավ աչքերի ներսում'}, {'label': 'back_pain', 'name': 'մեջքի ցավ'}, {'label': 'constipation', 'name': 'փորկապություն'}, {'label': 'abdominal_pain', 'name': 'որովայնային ցավ'}, {'label': 'diarrhoea', 'name': 'փորլուծություն'}, {'label': 'mild_fever', 'name': 'Մեղմ ցնցում'}, {'label': 'yellow_urine', 'name': 'դեղին մեզ'}, {'label': 'yellowing_of_eyes', 'name': 'դեղին աչքեր'}, {'label': 'acute_liver_failure', 'name': 'սուր լյարդի անբավարարություն'}, {'label': 'fluid_overload', 'name': 'հեղուկի գերբեռնվածություն'}, {'label': 'swelling_of_stomach', 'name': 'ստամոքսի այրոց'}, {'label': 'swelled_lymph_nodes', 'name': 'այտուցված ավիշ հանգույցներ'}, {'label': 'malaise', 'name': 'անբավարարություն'}, {'label': 'blurred_and_distorted_vision', 'name': 'լղոզված աղավաղված տեսողություն'}, {'label': 'phlegm', 'name': 'ֆլեգմա. լորձ, խորխ'}, {'label': 'throat_irritation', 'name': 'կոկորդի ցավ'}, {'label': 'redness_of_eyes', 'name': 'աչքերի կարմրություն'}, {'label': 'sinus_pressure', 'name': 'ճնշում'}, {'label': 'runny_nose', 'name': 'քթի արտահոսք '}, {'label': 'congestion', 'name': 'գերհոգնածություն'}, {'label': 'chest_pain', 'name': 'կրծքավանդակի ցավ'}, {'label': 'weakness_in_limbs', 'name': 'վերջույթների թուլություն'}, {'label': 'fast_heart_rate', 'name': 'սրտի  զարկերի արագացում'}, {'label': 'pain_during_bowel_movements', 'name': 'աղիքների ցավ շարժումների ժամանակ'}, {'label': 'pain_in_anal_region', 'name': 'ցավ անալ շրջանում'}, {'label': 'bloody_stool', 'name': 'արյունոտ կեղտ'}, {'label': 'irritation_in_anus', 'name': 'սրբանային գրգռում'}, {'label': 'neck_pain', 'name': 'պարանոցի ցավ, վզի ցավ'}, {'label': 'dizziness', 'name': 'գլխապտույտ'}, {'label': 'cramps', 'name': 'ցավեր'}, {'label': 'bruising', 'name': 'կապտուկ'}, {'label': 'obesity', 'name': 'ճարպակալում'}, {'label': 'swollen_legs', 'name': 'ուռած ոտքեր'}, {'label': 'swollen_blood_vessels', 'name': 'այտուցված արյան անոթներ'}, {'label': 'puffy_face_and_eyes', 'name': 'ուռած դեմք ու աչքեր'}, {'label': 'enlarged_thyroid', 'name': 'ուռած վահանաձև գեղձ'}, {'label': 'brittle_nails', 'name': 'փխրուն եղունգներ'}, {'label': 'swollen_extremeties', 'name': 'այտուցված վերջույթներ'}, {'label': 'excessive_hunger', 'name': 'շատակերություն, քաղց'}, {'label': 'extra_marital_contacts', 'name': 'լրացուցիչ ամուսնական կապեր'}, {'label': 'drying_and_tingling_lips', 'name': 'շրթունքների չորացում'}, {'label': 'slurred_speech', 'name': 'աղավաղված խոսք'}, {'label': 'knee_pain', 'name': 'ծնկի ցավ'}, {'label': 'hip_joint_pain', 'name': 'ազդրի ցավ'}, {'label': 'muscle_weakness', 'name': 'մկանների թուլություն '}, {'label': 'stiff_neck', 'name': 'ծուռ վիզ'}, {'label': 'swelling_joints', 'name': 'այտուցված հոդեր'}, {'label': 'movement_stiffness', 'name': 'շարժման խստություն'}, {'label': 'spinning_movements', 'name': 'պտտվող շարժումներ'}, {'label': 'loss_of_balance', 'name': 'հավասարակշռության կորուստ'}, {'label': 'unsteadiness', 'name': 'անկայունություն'}, {'label': 'weakness_of_one_body_side', 'name': 'մարմնի մեկ կողմի թուլություն'}, {'label': 'loss_of_smell', 'name': 'հոտի կորուստ'}, {'label': 'bladder_discomfort', 'name': 'միզապարկի տհաճություն'}, {'label': 'foul_smell_ofurine', 'name': 'մեզի տհաճ հոտ'}, {'label': 'continuous_feel_of_urine', 'name': 'հաճախակի միզելու զգացումցանկություն'}, {'label': 'passage_of_gases', 'name': 'գազեր'}, {'label': 'internal_itching', 'name': 'Ներքին քոր'}, {'label': 'toxic_look_(typhos)', 'name': 'վատ տեսք'}, {'label': 'depression', 'name': 'դեպրեսիա'}, {'label': 'irritability', 'name': 'դյուրագրգռություն'}, {'label': 'muscle_pain', 'name': 'մկանային ցավ'}, {'label': 'altered_sensorium', 'name': 'փոփոխված զգայնություն'}, {'label': 'red_spots_over_body', 'name': 'կարմիր բծեր մարմնի վրա'}, {'label': 'belly_pain', 'name': 'որովայնի ցավ, փորի ցավ, փորացավ'}, {'label': 'abnormal_menstruation', 'name': 'անկանոն դաշտան'}, {'label': 'dischromic_patches', 'name': 'խալեր'}, {'label': 'watering_from_eyes', 'name': 'թաց աչքեր, արցունքարտադրություն'}, {'label': 'increased_appetite', 'name': 'մեծ ախորժակ'}, {'label': 'polyuria', 'name': 'պոլիուրիա'}, {'label': 'family_history', 'name': 'ընտանիքի պատմություն'}, {'label': 'mucoid_sputum', 'name': 'թաց փռշտոց'}, {'label': 'rusty_sputum', 'name': 'խորխոտ փռշտոց'}, {'label': 'lack_of_concentration', 'name': 'չկարողանալ կենտրոնանալ'}, {'label': 'visual_disturbances', 'name': 'տեսողական խանգարումներ'}, {'label': 'receiving_blood_transfusion', 'name': 'ստացել եմ արյան փոխներարկում'}, {'label': 'receiving_unsterile_injections', 'name': 'ստացել եմ ոչ ստերիլ սրսկում'}, {'label': 'coma', 'name': 'կոմա'}, {'label': 'stomach_bleeding', 'name': 'ստամոքսի արյունահոսություն'}, {'label': 'distention_of_abdomen', 'name': 'ձգումներ որովայնի շրջանում'}, {'label': 'history_of_alcohol_consumption', 'name': 'ալկոհոլի չարաշահում, կախվածություն'}, {'label': 'blood_in_sputum', 'name': 'արյուն խորխի մեջ'}, {'label': 'prominent_veins_on_calf', 'name': 'արտահայտված երակներ'}, {'label': 'palpitations', 'name': 'սրտխփոցը'}, {'label': 'painful_walking', 'name': 'ցավ քայլելուց'}, {'label': 'pus_filled_pimples', 'name': 'թարախային բշտիկներ'}, {'label': 'blackheads', 'name': 'սև կետեր'}, {'label': 'scurring', 'name': 'քերվել'}, {'label': 'skin_peeling', 'name': 'մաշկի կլեպ'}, {'label': 'silver_like_dusting', 'name': 'արծաթանման փոշի'}, {'label': 'small_dents_in_nails', 'name': 'փոքրիկ խորշեր, անցքեր եղունգների մեջ'}, {'label': 'inflammatory_nails', 'name': 'բորբոքված եղունգներ'}, {'label': 'blister', 'name': 'բշտիկներ'}, {'label': 'red_sore_around_nose', 'name': 'կարմիր հատված քթի շուրջը'}, {'label': 'yellow_crust_ooze', 'name': 'դեղին կեղեւով վերք'}]\n"
     ]
    }
   ],
   "source": [
    "import tablib\n",
    "\n",
    "ds = tablib.Dataset()\n",
    "ds.csv = open(\"data/clean/disease_description.csv\").read()\n",
    "\n",
    "dictionary = dict(ds)\n",
    "# print(dictionary)\n",
    "models = list()\n",
    "\n",
    "for i in dictionary:\n",
    "    models.append( {\n",
    "\n",
    "        \"label\" : i.replace(\" \", \"\"),\n",
    "        \"name\" : dictionary[i]\n",
    "    })\n",
    "\n",
    "print(models)\n",
    "# return jsonify(models)\n",
    "# disease_description\n",
    "# print(dictionary['itching'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import tablib\n",
    "\n",
    "# load models\n",
    "loaded_model = pickle.load(open(\"finalized_model.sav\", \"rb\"))\n",
    "tfidf_vectorizer_model = pickle.load(open(\"tfidf_vectorizer_model.sav\", \"rb\"))\n",
    "multilabel_binarizer_model = pickle.load(open(\"multilabel_binarizer_model.sav\", \"rb\"))\n",
    "\n",
    "# load disease description\n",
    "ds = tablib.Dataset()\n",
    "ds.csv = open(\"data/clean/disease_description.csv\").read()\n",
    "disease_description = dict(ds)\n",
    "\n",
    "# methods\n",
    "def get_symtoms(text):\n",
    "    vec = tfidf_vectorizer_model.transform([text])\n",
    "    pred = loaded_model.predict(vec)\n",
    "    return multilabel_binarizer_model.inverse_transform(pred)\n",
    "\n",
    "\n",
    "# routes\n",
    "text = \"հետ տալ\"\n",
    "predicted_symptoms = get_symtoms(text)[0]\n",
    "\n",
    "models = list()\n",
    "for i in predicted_symptoms:\n",
    "    models.append( {\n",
    "        \"label\" : i.replace(\" \", \"\"),\n",
    "        \"name\" : disease_description[i.replace(\" \", \"\")]\n",
    "    })\n",
    "print(models)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
